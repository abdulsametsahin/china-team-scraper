{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4401a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import re\n",
    "import time\n",
    "import os, sys\n",
    "#pip install transformers==\"4.22.0\"\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import os, sys\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "def spliti(text):\n",
    "    l=text.split('\\n')\n",
    "    g=[]\n",
    "    for i in l :\n",
    "        x = re.sub('\\. ','.\\\\n', i)\n",
    "        x = re.sub('\\t','\\\\n', x)\n",
    "        g.append(x.split('\\n'))\n",
    "    k=[]\n",
    "    for i in g:\n",
    "        for j in i :\n",
    "            k.append(j)\n",
    "    return k\n",
    "def zho_ang(article):\n",
    "    tokenizer.src_lang = \"zho_Hans\"\n",
    "    G=[]\n",
    "    l=spliti(article)\n",
    "    #print(l)\n",
    "    for i in l :\n",
    "        encoded_hi = tokenizer(i, return_tensors=\"pt\")\n",
    "        generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"])\n",
    "        article_en=tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        #print(article_en[0])\n",
    "        for n in article_en :\n",
    "            G.append(n)\n",
    "    return ' '.join(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "739460f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "# mysql \n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "conn = mysql.connector.connect(host='43.198.99.5',database='scraper',port='3307', user= 'root', password='guest123')\n",
    "c = conn.cursor()\n",
    "import pandas as pd\n",
    "def apply_function_to_column():\n",
    "    \n",
    "    \n",
    "    # Apply the function to each value in the input column\n",
    "    values = pd.read_sql(\"SELECT id,title FROM companies where title is not null and english_name is null LIMIT 5\",conn)\n",
    "    values['title']=values['title'].apply(zho_ang)ca\n",
    "    print(values)\n",
    "\n",
    "\n",
    "    # Execute an UPDATE statement to set the values in the output column\n",
    "    for i,value in values.iterrows():\n",
    "        c.execute(f\"UPDATE companies SET english_name = '{value['title']}' WHERE id = '{value['id']}'\")\n",
    "        \n",
    "\n",
    "    # Commit the changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffb15956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omare\\AppData\\Local\\Temp\\ipykernel_25972\\3539680986.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  values = pd.read_sql(\"SELECT id,title FROM companies where title is not null and english_name is null LIMIT 5\",conn)\n",
      "C:\\Users\\omare\\.conda\\envs\\myenv\\lib\\site-packages\\transformers\\generation_utils.py:1227: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 200 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      id  \\\n",
      "0  0000986f-cd57-3e8c-9422-49da10ecfd161   \n",
      "1  0000a149-03e1-3790-87ef-34fe04eff4fc1   \n",
      "2  0000a63b-8279-3ce8-a2f6-169cd6c6a9861   \n",
      "3  0000aa8d-1d61-36be-9f87-f7970075224a1   \n",
      "4  0000b8dc-bb45-3c98-8cd7-562ca8c69d6f1   \n",
      "\n",
      "                                               title  \n",
      "0  Bridge and woodworking plant in Jiangxi, Chong...  \n",
      "1  The company is owned by the Chinese mining com...  \n",
      "2                      Hongqing County Labor Limited  \n",
      "3  Liangping County Minda Town Grain Processing P...  \n",
      "4  Employee Technical Cooperation Services of the...  \n",
      "id                   0000986f-cd57-3e8c-9422-49da10ecfd161\n",
      "title    Bridge and woodworking plant in Jiangxi, Chong...\n",
      "Name: 0, dtype: object\n",
      "id                   0000a149-03e1-3790-87ef-34fe04eff4fc1\n",
      "title    The company is owned by the Chinese mining com...\n",
      "Name: 1, dtype: object\n",
      "id       0000a63b-8279-3ce8-a2f6-169cd6c6a9861\n",
      "title            Hongqing County Labor Limited\n",
      "Name: 2, dtype: object\n",
      "id                   0000aa8d-1d61-36be-9f87-f7970075224a1\n",
      "title    Liangping County Minda Town Grain Processing P...\n",
      "Name: 3, dtype: object\n",
      "id                   0000b8dc-bb45-3c98-8cd7-562ca8c69d6f1\n",
      "title    Employee Technical Cooperation Services of the...\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "apply_function_to_column()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
